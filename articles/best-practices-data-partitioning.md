<properties
   pageTitle="Recommandations en matière de partitionnement | Microsoft Azure"
   description="Recommandations concernant le fractionnement de partitions pour une gestion et un accès distincts."
   services=""
   documentationCenter="na"
   authors="dragon119"
   manager="masimms"
   editor=""
   tags=""/>

<tags
   ms.service="best-practice"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="na"
   ms.date="12/20/2015"
   ms.author="masashin"/>

# Recommandations en matière de partitionnement des données

![](media/best-practices-data-partitioning/pnp-logo.png)

## Vue d’ensemble

Au sein de nombreuses solutions à grande échelle, les données sont divisées en partitions distinctes qui peuvent être gérées et accessibles séparément. La stratégie de partitionnement doit être choisie avec soin afin d’optimiser les avantages tout en réduisant les effets négatifs. Le partitionnement peut aider à améliorer l’évolutivité, réduire la contention et optimiser les performances. Un avantage annexe du partitionnement consiste en sa capacité à fournir un mécanisme permettant de diviser des données selon le modèle d’utilisation. Vous pouvez archiver les données anciennes et moins actives pour réduire les frais liés au stockage des données.

## Pourquoi partitionner les données ?

La plupart des services et applications cloud stockent et récupèrent des données dans le cadre de leurs opérations. La conception des magasins de données utilisés par une application peut avoir une incidence considérable sur les performances, le débit et l’évolutivité d’un système. Une technique couramment appliquée dans les systèmes à grande échelle consiste à diviser les données en partitions distinctes.

> Le terme _partitionnement_ utilisé dans ces recommandations désigne le processus de division physique des données au sein de magasins de données distincts. Il ne s’agit pas du même concept de partitionnement de tables SQL Server, lequel est différent.

Le partitionnement des données présente un certain nombre d’avantages. Par exemple, il peut être utilisé pour :

- **Améliorer l’évolutivité** : la mise à l’échelle d’un système de base de données unique finit par atteindre une limite en termes de matériel physique. Le fait de diviser les données en plusieurs partitions, chacune étant hébergée sur un serveur distinct, permet au système d’évoluer presque à l’infini.
- **Améliorer les performances** : les opérations d’accès aux données présentes au sein de chaque partition interviennent sur un plus petit volume de données. Si les données sont partitionnées de manière appropriée, ces opérations se révèlent bien plus efficaces. Les opérations concernant plusieurs partitions peuvent s’exécuter en parallèle. Chaque partition peut être située près de l’application qui l’utilise afin de réduire la latence du réseau.
- **Améliorer la disponibilité** : le fait de diviser les données au sein plusieurs serveurs permet de ne pas disposer d’un point de défaillance unique. Si un serveur tombe en panne ou est en cours de maintenance planifiée, seules les données présentes au sein de cette partition ne sont pas disponibles. Les opérations intervenant sur les autres partitions peuvent se poursuivre. Le fait d’augmenter le nombre de partitions réduit l’impact relatif lié à la défaillance d’un serveur unique en réduisant le pourcentage des données qui ne seront pas disponibles. La réplication de chaque partition permet de réduire le risque d’une défaillance de partition unique qui affecterait les opérations. Cela permet également de séparer les données critiques qui doivent être hautement disponibles en permanence des données de faible valeur (telles que des fichiers journaux), lesquelles présentent des exigences de disponibilité moindres.
- **Améliorer la sécurité** : selon la nature des données et la manière dont elles sont partitionnées, il peut être possible de séparer les données sensibles et non sensibles en différentes partitions et par conséquent différents serveurs ou magasins de données. Il est ensuite possible d’optimiser le sécurité de manière spécifique concernant les données sensibles.
- **Disposer d’une flexibilité opérationnelle** : le partitionnement offre de nombreuses opportunités en matière de réglage précis des opérations, d’optimisation de l’efficacité de l’administration et de réduction des coûts. Il est, par exemple, possible de définir différentes stratégies relatives à la gestion, la surveillance, la sauvegarde et la restauration, ainsi que concernant d’autres tâches d’administration en fonction de l’importance des données présentes au sein de chaque partition.
- **Faire correspondre le magasin de données au modèle d’utilisation** : le partitionnement permet le déploiement de chaque partition sur un type de magasin de données différent, en fonction du coût et des fonctionnalités intégrées proposées par le magasin de données. Par exemple, il est possible de stocker les données binaires volumineuses au sein d’un magasin de données blob, et de stocker les données plus structurées au sein d’une base de données de document. Pour plus d’informations, consultez la section (en anglais) [Building a Polyglot Solution] du guide des modèles et pratiques [Data Access for Highly-Scalable Solutions: Using SQL, NoSQL, and Polyglot Persistence] disponible sur le site Web de Microsoft.

Certains systèmes ne mettent pas en œuvre le partitionnement, car cette technique est considérée comme une charge supplémentaire plutôt qu’un avantage. Les arguments courants motivant ce point de vue sont les suivants :

- De nombreux systèmes de stockage de données ne prennent pas en charge les jointures entre les partitions, et il peut s’avérer difficile de maintenir l’intégrité référentielle au sein d’un système partitionné. Il est souvent nécessaire de mettre en œuvre des jointures et vérifications de l’intégrité dans le code applicatif (au niveau de la couche de partitionnement), ce qui peut conduire à une augmentation des E/S et une complexité applicative supplémentaire.
- La maintenance des partitions ne se révèle pas toujours aisée. Au sein d’un système où les données sont volatiles, il vous faudra peut-être régulièrement rééquiliber les partitions afin de réduire la contention et les zones sensibles.
- Certains outils courants ne fonctionnent pas naturellement avec des données partitionnées.

## Concevoir des partitions

Il est possible de partitionner les données de différentes manières : horizontale, verticale ou fonctionnelle. La stratégie que vous choisissez dépend des motifs du partitionnement des données et des besoins des applications et services qui utilisent ces données.

> [AZURE.NOTE]Les schémas de partitionnement décrits dans ces recommandations sont expliqués indépendamment de la technologie de stockage de données sous-jacente. Ces schémas peuvent être appliqués à de nombreux types de magasins de données, notamment les bases de données relationnelles et NoSQL.

### Stratégies de partitionnement

Les trois stratégies de partitionnement des données habituelles sont les suivantes :

- **Partitionnement horizontal** (souvent appelé _sharding_) : concernant cette stratégie, chaque partition correspond à un magasin de données à part entière, mais toutes les partitions présentent le même schéma. Chaque partition est appelée _shard_ et comporte un sous-ensemble spécifique des données, telles que l’ensemble des commandes relatives à un jeu spécifique de clients au sein d’une application de commerce électronique.
- **Partitionnement vertical** : concernant cette stratégie, chaque partition comporte un sous-ensemble des champs relatifs aux éléments présents au sein du magasin de données. Les champs sont divisés selon leur modèle d’utilisation. On place, par exemple, les champs fréquemment utilisés au sein d’une partition verticale et les champs moins fréquemment utilisés au sein d’une autre partition verticale.
- **Partitionnement fonctionnel** : concernant cette stratégie, les données sont agrégées en fonction de leur utilisation par chaque contexte limité au sein du système. Par exemple, un système de commerce électronique mettant en œuvre des fonctions d’entreprise distinctes pour la facturation et la gestion de l’inventaire des produits peut stocker les données de facturation au sein d’une partition et les données relatives à l’inventaire des produits au sein d’une autre partition.

Il est important de noter qu’il est possible d’associer les trois stratégies décrites. Elles ne sont pas mutuellement exclusives et vous devez les considérer dans leur ensemble lorsque vous concevez un schéma de partitionnement. Vous pouvez, par exemple, diviser les données en partitions, puis utiliser le partitionnement vertical pour ensuite sous-diviser les données au sein de chaque partition. De même, il est possible de diviser les données présentes au sein d’une partition fonctionnelle en partitions (lesquelles peuvent également faire l’objet d’un partitionnement vertical).

Toutefois, les différentes exigences propres à chaque stratégie peuvent présenter un certain nombre d’enjeux conflictuels qu’il vous faut évaluer et mesurer lors de la conception d’un schéma de partitionnement répondant à l’ensemble des objectifs de performance de traitement des données globales de votre système. Les sections qui suivent décrivent chacune des stratégies plus en détail.

### Partitionnement horizontal (sharding)

La figure 1 présente une vue d’ensemble du partitionnement horizontal ou sharding. Dans cet exemple, les données relatives à l’inventaire des produits sont divisées en partitions en fonction de la clé du produit. Chaque partition comporte les données relatives à une plage contiguë de clés de partition (A à G et H à Z), classées par ordre alphabétique.

![](media/best-practices-data-partitioning/DataPartitioning01.png)

_Figure 1 : Partitionnement horizontal des données (sharding) en fonction de la clé de la partition_

Le partitionnement vous permet de répartir la charge sur davantage d’ordinateurs afin de réduire la contention et d’améliorer les performances. Vous pouvez faire évoluer le système en ajoutant des partitions s’exécutant sur des serveurs supplémentaires.

Le facteur le plus important lors de la mise en œuvre de cette stratégie de partitionnement correspond au choix de la clé de partitionnement. Il peut s’avérer difficile de modifier la clé une fois le système est en fonctionnement. La clé doit garantir un partitionnement des données permettant de disposer d’une charge de travail aussi homogène que possible au sein des partitions. Remarquez que différentes partitions ne doivent pas nécessaire comporter des volumes de données similaires. Le plus important étant d’équilibrer le nombre de demandes : certaines partitions peuvent être très volumineuses, mais chaque élément fait l’objet d’un faible nombre d’opérations d’accès, tandis que d’autres partitions peuvent être moins volumineuses, mais chaque élément est beaucoup plus fréquemment sollicité. Il est également important de s’assurer qu’une partition ne dépasse pas les limites permises par la mise à l’échelle (en termes de capacité et de ressources de traitement) du magasin de données utilisé pour héberger cette partition.

Le schéma de partitionnement doit également éviter de créer des zones sensibles (ou partitions actives) pouvant avoir des répercussions sur les performances et la disponibilité. Par exemple, l’utilisation d’un hachage d’un ID client plutôt que la première lettre de son nom permet d’éviter une répartition non équilibrée due à l’utilisation d’initiales plus ou moins courantes. Il s’agit d’une technique standard qui permet de répartir les données de manière plus homogène entre les partitions.

La clé de partitionnement que vous choisissez doit permettre de réduire toute exigence ultérieure en matière de fractionnement de partitions volumineuses en plus petits éléments, de regroupement de petites partitions en partitions plus volumineuses ou de modification du schéma décrivant les données stockées au sein d’un jeu de partitions. Ces opérations peuvent prendre beaucoup de temps et nécessiter la déconnexion d’une ou plusieurs partitions pendant leur exécution. Si les partitions sont répliquées, il peut être possible de maintenir la connexion de certaines des répliques alors que d’autres sont fractionnées, fusionnées ou reconfigurées, mais il se peut que le système doive limiter les opérations pouvant être réalisées sur les données au sein de ces partitions au cours de la reconfiguration. Il est , par exemple, possible de marquer les données présentes au sein des répliques lecture seule afin de limiter la portée de toute incohérence qui, autrement, pourrait se produire au cours de la restructuration des partitions.

> Pour obtenir plus d’informations et des conseils sur la plupart de ces considérations, ainsi que des techniques de bonnes pratiques en matière de conception des magasins de données mettant en œuvre un partitionnement horizontal, consultez la section (en anglais) [Sharding Pattern].

### Partitionnement vertical

L’utilisation la plus courante du partitionnement vertical vise à réduire les E/S et les coûts de performance associés à la recherche des éléments les plus fréquemment utilisés. La figure 2 présente une vue d’ensemble d’un exemple de partitionnement vertical, au sein duquel différentes propriétés relatives à chaque élément de données sont présentes au sein de partitions différentes : le nom, la description et les informations tarifaires des produits sont plus fréquemment sollicités que le volume en stock ou la dernière date de commande.

![](media/best-practices-data-partitioning/DataPartitioning02.png)

_Figure 2 : Partitionnement vertical des données en fonction du modèle d’utilisation_

Dans cet exemple, l’application interroge régulièrement le nom du produit, sa description et son prix de manière conjointe lors de la présentation des détails des produits aux clients. Le niveau des stocks et la date de dernière commande du produit auprès du fabricant sont stockés au sein d’une partition distincte, ces deux éléments étant généralement utilisés conjointement. Ce schéma de partitionnement présente l’avantage de séparer les données relativement lentes (nom, description et prix du produit) des données plus dynamiques (niveau de stock et dernière date de commande). Une application peut tirer parti de la mise en mémoire cache des données lentes si elles sont fréquemment sollicitées.

Un autre scénario habituel concernant cette stratégie de partitionnement consiste à optimiser la sécurité des données sensibles. Par exemple, en stockant les numéros de carte de crédit et les numéros de vérification correspondants dans des partitions distinctes.

Le partitionnement vertical peut également réduire l’importance des accès simultanés nécessaires aux données.

> Le partitionnement vertical fonctionne au niveau de l’entité au sein d’un magasin de données, en normalisant partiellement une entité pour organiser un _large_ élément en un jeu d’éléments _restreints_. Il est parfaitement adapté aux magasins de données organisés en colonnes, tels que HBase et Cassandra. Si les données présentes au sein d’une collection de colonnes sont peu susceptibles d’être modifiées, vous pouvez également envisager d’utiliser des magasins organisés en colonnes dans SQL Server.

### Partitionnement fonctionnel

Concernant les systèmes au sein desquels il est possible d’identifier un contexte limité pour chaque secteur d’activité ou service au sein de l’application, le partitionnement fonctionnel constitue une technique permettant d’améliorer les performances en matière d’isolement et d’accès aux données. Une autre utilisation courante du partitionnement fonctionnel consiste à séparer les données en lecture-écriture des données en lecture seule utilisées pour générer des rapports. La figure 3 présente une vue d’ensemble du partitionnement fonctionnel au sein duquel les données d’inventaire sont séparées des données relatives aux clients.

![](media/best-practices-data-partitioning/DataPartitioning03.png)

_Figure 3 : Partitionnement fonctionnel des données en fonction du contexte limité ou du sous-domaine_

Cette stratégie de partitionnement permet de réduire la contention des accès aux données au sein de différents composants du système.

## Concevoir des partitions évolutives

Il est essentiel de tenir compte de la taille et de la charge de travail de chaque partition et de les équilibrer afin que les données soient réparties de manière à assurer une évolutivité maximale. Cependant, vous devez également partitionner les données de sorte qu’elles ne dépassent pas les limites d’échelle d’un magasin de partitions.

Procédez comme suit lorsque vous concevez les partitions pour garantir leur évolutivité :

1. Analysez l’application pour comprendre les modèles d’accès aux données, telles que la taille du jeu de résultats renvoyé par chaque requête, la fréquence d’accès, la latence inhérente et les exigences de traitement côté serveur. Dans de nombreux cas, seules quelques entités principales nécessitent la majorité des ressources de traitement.
2. Selon cette analyse, déterminez les objectifs d’évolutivité actuels et futurs, tels que la taille des données et de la charge de travail, et répartissez les données entre les partitions afin de répondre à l’objectif d’évolutivité. Concernant la stratégie de partitionnement horizontal, le choix de la clé de partitionnement appropriée est important pour s’assurer de l’homogénéité de la répartition. Pour en savoir plus, consultez la section (en anglais) [Sharding pattern].
3. Assurez-vous que les ressources disponibles pour chaque partition sont suffisantes pour traiter les exigences d’évolutivité en termes de débit et de taille des données. Par exemple, le nœud qui héberge une partition peut imposer une limite stricte concernant la quantité d’espace de stockage, la puissance de traitement ou la bande passante réseau qu’il fournit. Si les exigences relatives au traitement et au stockage des données sont susceptibles de dépasser ces limites, il peut s’avérer nécessaire d’affiner votre stratégie de partitionnement ou de fractionner davantage les données. Par exemple, une approche en matière d’évolutivité peut consister à séparer les données de journalisation des principales fonctionnalités applicatives à l’aide de magasins de données distincts afin d’éviter que les exigences concernant le stockage total des données ne dépassent la limite de mise à l’échelle du nœud. Si le nombre total de magasins de données dépasse la limite de nœud, il peut être nécessaire d’utiliser des nœuds de stockage distincts.
4. Surveillez le système lorsqu’il est en fonctionnement afin de vérifier que les données sont réparties comme prévu et que les partitions peuvent gérer la charge qui leur est affectée. Il est possible que l’utilisation ne corresponde pas aux prévisions de l’analyse. Vous pouvez alors rééquilibrer les partitions. En cas d’échec, il peut s’avérer nécessaire de redéfinir certains composants du système pour procéder à un équilibrage approprié.

Remarquez que certains environnements cloud allouent les ressources en fonction des limites de l’infrastructure, et que vous devez vérifier que les limites sélectionnées fournissent assez d’espace pour permettre toute croissance anticipée en termes de volume de données, de stockage des données, de puissance de traitement et de bande passante. Par exemple, si vous utilisez Azure Table Storage, une partition en cours d’utilisation peut nécessiter davantage de ressources que celles disponibles pour une partition unique afin de gérer les demandes (il existe une limite pour le volume de demandes pouvant être gérées par une partition unique dans une période donnée, pour plus d’informations, consultez la page [Objectifs de performance et évolutivité d’Azure Storage] sur le site Web de Microsoft). Dans ce cas, il se peut que vous deviez repartitionner la partition pour répartir la charge. Si la taille totale ou le débit de ces tables dépasse la capacité d’un compte de stockage, il peut être nécessaire de créer des comptes de stockage supplémentaires et de répartir les tables sur ces comptes. Si le nombre de comptes de stockage dépasse le nombre de comptes disponibles pour un abonnement, il peut être nécessaire d’utiliser plusieurs abonnements.

## Concevoir des partitions pour garantir la performance des requêtes

La performance des requêtes peut souvent être améliorée grâce à l’utilisation de plus petits jeux de données et une exécution de requêtes parallèles. Chaque partition doit comporter une petite proportion de l’ensemble du jeu de données, et cette réduction de volume peut améliorer la performance des requêtes. Cependant, le partitionnement n’est pas une alternative permettant de concevoir et de configurer une base de données de manière appropriée. Assurez-vous, par exemple, que vous disposez des index nécessaires si vous utilisez une base de données relationnelle.

Procédez comme suit lorsque vous concevez les partitions pour garantir la performance des requêtes :

1. Examinez les exigences et les performances applicatives :
	- Utilisez les exigences fonctionnelles afin de déterminer les requêtes essentielles devant toujours être réalisées rapidement.
	- Surveillez le système afin d’identifier les requêtes s’exécutant lentement.
	- Identifiez les requêtes les plus fréquemment exécutées. Une seule instance de chaque requête peut correspondre à un coût minime, mais la consommation cumulée de ressources peut être considérable. Il peut s’avérer utile de séparer les données récupérées par ces requêtes au sein d’une partition distincte, voire en mémoire cache.
2. Partitionnez les données à l’origine du ralentissement des performances. Vérifiez les points suivants :
	- Limitez la taille de chaque partition afin que le temps de réponse aux requêtes corresponde à l’objectif.
	- Concevez la clé de partitionnement de sorte que l’application puisse aisément trouver la partition si vous mettez en œuvre un partitionnement horizontal. Vous n’obligez ainsi pas la requête à parcourir chaque partition.
	- Réfléchissez à l’emplacement d’une partition concernant la performance des requêtes. Si possible, essayez de conserver les données au sein de partitions physiquement proches des applications et utilisateurs qui y accèdent.
3. Si une entité présente des exigences en matière de débit et de performance des requêtes, utilisez le partitionnement fonctionnel en vous basant sur cette entité. Si cela ne permet toujours pas de satisfaire aux exigences, utilisez également un partitionnement horizontal. Dans la plupart des cas, une seule stratégie de partitionnement suffit, mais dans certains cas, il s’avère plus efficace d’associer les deux stratégies.
4. Envisagez d’utiliser des requêtes asynchrones s’exécutant en parallèle sur plusieurs partitions pour améliorer les performances.

## Concevoir des partitions évolutives

Le fait de partitionner des données peut améliorer la disponibilité des applications en veillant à ce que l’ensemble du jeu de données ne constitue pas un point de défaillance unique et que les sous-ensembles individuels du jeu de données puissent être gérés indépendamment. La réplication des partitions comportant les données essentielles peut également améliorer la disponibilité.

Lors de la conception et de la mise en œuvre des partitions, tenez compte des facteurs suivants qui affectent la disponibilité :

- Importance des données concernant les opérations d’exploitation. Certaines données peuvent comporter des informations essentielles, telles que des détails de facture ou des transactions bancaires. D’autres données peuvent se révéler moins essentielles, telles que les fichiers journaux, les suivis des performances, etc. Après avoir identifié le type des données, considérez les points suivants :
	- Stockage des données critiques au sein de partitions hautement disponibles avec un plan de sauvegarde approprié.
	- Établissement de mécanismes ou procédures de gestion et de surveillance distincts selon l’importance de chaque jeu de données. Placez les données présentant le même niveau d’importance au sein de la même partition afin de pouvoir les sauvegarder conjointement à intervalles appropriés. Par exemple, les partitions comportant les données relatives aux transactions bancaires doivent être sauvegardées plus fréquemment que les partitions comportant les fichiers journaux ou les informations de suivi.
- Gestion des partitions individuelles. Le fait de créer des partitions venant favoriser une gestion et une maintenance indépendantes présente plusieurs avantages. Par exemple :
	- En cas de défaillance d’une partition, elle peut être récupérée de manière indépendante, sans affecter les instances des applications accédant aux données présentes au sein des autres partitions.
	- Le partitionnement des données par zone géographique peut permettre l’exécution des tâches de maintenance planifiée au cours des heures creuses de chaque emplacement. Assurez-vous que les partitions ne sont pas trop volumineuses pour empêcher l’exécution de toute maintenance planifiée au cours de cette période.
- Réplication des données critiques au sein de plusieurs partitions. Cette stratégie peut améliorer la disponibilité et les performances, bien qu’elle puisse également présenter certains problèmes de cohérence. La synchronisation des modifications apportées aux données au sein d’une partition sur toutes les répliques prend du temps, et pendant ce temps, les différentes partitions intègrent différentes valeurs de données.

## Problèmes et considérations

L’utilisation du partitionnement complique la conception et le développement du système. Il est important de considérer le partitionnement comme un composant fondamental de la conception du système, même si le système ne comporte au départ qu’une seule partition. L’idée de bénéficier du partitionnement après coup, une fois que le système commence à présenter des problèmes de performance et d’évolutivité ne fait qu’accroître la complexité, dans la mesure où vous disposez probablement d’un système actif dont vous devez assurer la maintenance. La mise à jour du système afin d’intégrer le partitionnement dans cet environnement nécessite non seulement la modification de la logique d’accès aux données, mais peut également impliquer la migration d’importants volumes de données existantes afin de les répartir au sein des partitions, alors même que les utilisateurs s’attendent à pouvoir continuer à utiliser le système.

Dans certains cas, le partitionnement n’est pas considéré comme un élément important, le jeu de données initial étant peu volumineux et pouvant être facilement traité par un seul serveur. Cela peut s’avérer être le cas concernant un système dont l’évolution n’est pas prévue au-delà de sa taille initiale, mais de nombreux systèmes commerciaux doivent pouvoir évoluer à mesure que le nombre d’utilisateurs augmente. Cette évolution est généralement accompagnée d’une croissance du volume de données. Vous devez également comprendre que le partitionnement n’est pas toujours réservé à d’importants magasins de données. Par exemple, un magasin de données de petite taille peut faire l’objet d’accès de la part de centaines de clients simultanés. Le fait de partitionner les données dans une telle situation peut aider à réduire la contention et améliorer le débit.

Considérez les points suivants lorsque vous concevez un schéma de partitionnement de données :

- Si possible, conservez les données relatives aux opérations de base de données les plus courantes au sein de chaque partition afin de réduire les opérations d’accès aux données entre partitions. Le fait d’interroger plusieurs partitions peut se révéler plus long que d’interroger une seule partition, mais l’optimisation des partitions d’un jeu de requêtes peut, au contraire, affecter les autres jeux de requêtes. Pour réduire la durée des requêtes au sein de plusieurs partitions lorsque c’est indispensable, exécutez des requêtes parallèles au sein des partitions et agrégez les résultats au sein de l’application. Dans certains cas, il se peut cependant que cette approche ne soit pas possible, par exemple lorsqu’il est nécessaire d’obtenir un résultat d’une requête et de l’utiliser dans la requête suivante.
- Si les requêtes utilisent des données de référence relativement statiques, telles que des tables de codes postaux ou les listes de produits, envisagez de répliquer ces données au sein de toutes les partitions afin de réduire la nécessité d’une opération de recherche distincte au sein d’une autre partition. Cette approche peut également réduire le risque que les données de référence deviennent un jeu de données sensible, sujet à un trafic dense au sein de l’ensemble du système, bien que la synchronisation de toutes les modifications pouvant être apportées à ces données de référence présente un coût supplémentaire.
- Dans la mesure du possible, réduisez les exigences en matière d’intégrité référentielle au sein des partitions verticales et fonctionnelles. Dans ces schémas, l’application elle-même est chargée de maintenir l’intégrité référentielle au sein des partitions lorsque les données sont mises à jour et utilisées. Les requêtes devant consulter des données présentes au sein de plusieurs partitions s’exécutent plus lentement que les requêtes consultant des données présentes au sein d’une même partition, car l’application doit généralement effectuer des requêtes consécutives basées sur une clé, puis sur une clé étrangère. Envisagez plutôt de répliquer ou de dénormaliser les données pertinentes. Pour réduire la durée des requêtes consultant plusieurs partitions, exécutez des requêtes parallèles sur les partitions et agrégez les données au sein de l’application.
- Considérez l’effet possible du schéma de partitionnement sur la cohérence des données au sein des partitions. Vous devez déterminer si une importante cohérence constitue une réelle exigence. Une approche courante alternative dans le cloud consiste à mettre en œuvre une cohérence finale. Les données présentes au sein de chaque partition sont mises à jour séparément, et la logique applicative peut se charger de vérifier la bonne réussite des mises à jour, ainsi que de gérer les incohérences pouvant survenir lors de l’interrogation des données au cours de l’exécution d’une opération de cohérente finale. Pour plus d’informations concernant la mise en œuvre de la cohérence finale, consultez le Guide de cohérence « Consistency Guidance ». (#lien à insérer#)
- Envisagez la méthode de localisation de la partition appropriée par les requêtes. Si une requête doit parcourir toutes les partitions pour localiser les données souhaitées, cela affecte considérablement les performances, même en cas d’utilisation de plusieurs requêtes en parallèle. Les requêtes utilisées avec les stratégies de partitionnement vertical et fonctionnel peuvent spécifier naturellement les partitions. Cependant, lorsque vous utilisez le partitionnement horizontal (sharding), la localisation d’un élément peut s’avérer difficile, chaque partition présentant le même schéma. Une solution de partitionnement classique consiste à actualiser une carte pouvant être utilisée pour rechercher l’emplacement de la partition afin de consulter des éléments de données spécifiques. Il est possible de mettre cette carte en œuvre au sein de la logique de partitionnement de l’application ou de l’actualiser à l’aide du magasin de données s’il prend en charge le partitionnement transparent.
- Lorsque vous utilisez une stratégie de partitionnement horizontal, envisagez de rééquilibrer régulièrement les partitions pour répartir les données de manière homogène en fonction de leur taille et de la charge de travail afin de réduire les zones sensibles, d’optimiser la performance des requêtes et de contourner les limites de stockage physique. Il s’agit cependant d’une tâche complexe qui nécessite souvent l’utilisation d’un processus ou d’un outil personnalisé.
- Le fait de répliquer chaque partition permet de disposer d’une protection supplémentaire contre les défaillances. Si une réplique connaît une défaillance, les requêtes peuvent être dirigées vers une copie de travail.
- Si vous atteignez les limites physiques d’une stratégie de partitionnement, il vous faut peut-être étendre l’évolutivité à un autre niveau. Par exemple, si le partitionnement intervient au niveau de la base de données, il peut s’agir de placer ou de répliquer les partitions au sein de plusieurs bases de données. Si le partitionnement intervient déjà au niveau de la base de données et que les limitations physiques posent problème, il peut s’agir de placer ou de répliquer les partitions au sein de plusieurs comptes d’hébergement.
- Évitez les transactions qui accèdent à des données présentes au sein de plusieurs partitions. Certains magasins de données mettent en œuvre l’intégrité et la cohérence transactionnelles pour les opérations venant modifier les données, mais uniquement lorsque ces données sont présentes au sein d’une seule partition. Si vous devez disposer d’une prise en charge au sein de plusieurs partitions, il vous faut probablement mettre en œuvre ce mécanisme en l’intégrant à votre logique applicative, la plupart des systèmes de partitionnement ne proposant pas de prise en charge native.

Tous les magasins de données nécessitent une certaine gestion opérationnelle et une certaine surveillance. Les tâches associées peuvent aller du chargement, de sauvegarde, de la restauration et de la réorganisation des données à la vérification du fonctionnement correct et efficace du système.

Tenez compte des facteurs suivants qui affectent la gestion des opérations :

- Envisagez la méthode de mise en œuvre des tâches de gestion et de fonctionnement appropriées, telles que la sauvegarde, la restauration et l’archivage des données, ainsi que la surveillance du système, une fois les données partitionnées. Par exemple, la maintenance de la cohérence logique au cours des opérations de sauvegarde et de restauration peut se révéler compliquée.
- Méthode de chargement des données au sein de plusieurs partitions et méthode d’ajout de nouvelles données issues d’autres sources. Il se peut que certains outils et utilitaires ne prennent pas en charge certaines opérations relatives à des données partitionnées, telles que le chargement des données au sein de la partition appropriée, nécessitant donc la création ou l’obtention de nouveaux outils et utilitaires.
- Méthode d’archivage et de suppression des données de manière régulière (peut-être chaque mois) afin d’éviter l’évolution excessive des partitions. Il peut être nécessaire de transformer les données pour correspondre à un schéma d’archivage différent.
- Envisagez d’exécuter un processus périodique permettant d’identifier tout problème d’intégrité des données, par des données présentes au sein d’une seule partition faisant référence à des informations présentes au sein d’une autre, mais ces informations sont manquantes. Le processus peut soit tenter de résoudre ces problèmes automatiquement, soit déclencher une alerte auprès d’un opérateur pour qu’il corrige manuellement les problèmes. Par exemple, au sein d’une application de commerce électronique, les informations relatives aux commandes peuvent être stockées au sein d’une partition, mais les éléments de ligne constituant chaque commande peuvent être stockés au sein d’une autre partition. Le processus de passation de commandes doit ajouter des données aux deux partitions. Si ce processus échoue, il se peut que certains éléments de ligne stockés ne correspondent à aucune commande.

Les différentes technologies de stockage de données fournissent généralement leurs propres fonctionnalités pour prendre en charge le partitionnement. Les sections suivantes résument les options mises en œuvre par les magasins de données utilisés par les applications Azure et décrivent les considérations relatives à la conception d’applications pouvant tirer le meilleur parti de ces fonctionnalités.

## Stratégies de partitionnement pour Base de données SQL Azure

Base de données SQL Azure correspond à une base de données en tant que service relationnel s’exécutant dans le cloud. Ce service est basé sur Microsoft SQL Server. Une base de données relationnelle divise les informations en différentes tables, chacune de ces tables comprenant des informations relatives aux entités sous forme de séries de lignes. Chaque ligne comporte des colonnes qui contiennent les données relatives aux champs individuels d’une entité. La page [Qu’est-ce qu’une base de données SQL Azure ?] sur le site Web de Microsoft présente des informations détaillées concernant la création et l’utilisation de bases de données SQL.

## Partitionnement horizontal avec la fonction Base de données élastique

Une base de données SQL unique présente une limite concernant le volume de données qu’elle peut contenir et le débit est limité par les facteurs architecturaux et le nombre de connexions simultanées prises en charge. Base de données SQL Azure propose la fonction Base de données élastique afin de prendre en charge la mise à l’échelle horizontale d’une base de données SQL. Grâce à la fonction Base de données élastique, vous pouvez partitionner vos données en partitions réparties sur plusieurs bases de données SQL et vous pouvez ajouter ou supprimer des partitions à mesure que le volume de données que vous devez gérer augmente ou diminue. La fonction Base de données élastique permet également de réduire la contention en répartissant la charge entre les bases de données.

> [AZURE.NOTE]La fonction Base de données élastique est actuellement en version préliminaire depuis décembre 2015. Elle vient remplacer la fonction Fédérations pour Base de données SQL Azure, qui sera supprimée. Les installations Fédérations pour Base de données SQL Azure existantes peuvent être migrées vers une base de données élastique à l’aide de l’[utilitaire de migration de fédérations]. Vous pouvez également mettre en œuvre votre propre mécanisme de partitionnement si votre système ne se prête pas naturellement aux fonctionnalités offertes par les bases de données élastiques.

Chaque partition est mise en œuvre sous forme de base de données SQL. Une partition peut contenir plus d’un jeu de données (appelé _shardlet_), et chaque base de données conserve les métadonnées décrivant les shardlets qu’elle contient. Un shardlet peut correspondre à un seul élément de données ou à un groupe d’éléments partageant la même clé de shardlet. Par exemple, si vous procédez au partitionnement de données au sein d’une application mutualisée, la clé de shardlet peut correspondre à l’ID client, et toutes les données relatives à un client seront stockées au sein du même shardlet. Les données relatives aux autres clients seront stockées au sein de différents shardlets.

Il incombe au programmeur d’associer un groupe de données à une clé de shardlet. Une base de données SQL distincte fonctionne comme un gestionnaire global des cartes des partitions, lesquelles comportent une liste des bases de données (partitions) qui constituent l’ensemble du système, ainsi que des informations relatives aux shardlets présents au sein de chaque base de données. Une application cliente qui accède aux données se connecte d’abord au gestionnaire global des cartes des partitions pour obtenir une copie de la carte (répertoriant les partitions et les shardlets) qu’il place en mémoire cache locale. L’application utilise ensuite ces informations pour acheminer les demandes de données vers la partition appropriée. Cette fonctionnalité est masquée derrière une série d’API présentes dans la Bibliothèque cliente Base de données élastique Base de données SQL Azure, disponible sous forme de package NuGet. La page [Vue d’ensemble des fonctionnalités de bases de données élastiques] sur le site Web de Microsoft dresse une présentation plus complète de la fonction Base de données élastique.

> [AZURE.NOTE]Vous pouvez répliquer la base de données du gestionnaire global des cartes des partitions pour réduire la latence et améliorer la disponibilité. Si vous mettez en œuvre la base de données à l’aide de l’un des niveaux de tarification Premium, vous pouvez configurer la géoréplication active afin de copier des données en continu dans des bases de données présentes au sein de différentes régions. Créez une copie de la base de données dans chaque région dans laquelle les utilisateurs se trouvent et configurez votre application pour qu’elle se connecte à cette copie afin d’obtenir la carte des partitions.

> Une autre approche consiste à utiliser la Synchronisation des données SQL Azure ou un pipeline Azure Data Factory pour répliquer la base de données du gestionnaire de la carte des partitions dans les différentes régions. Cette forme de réplication s’exécute périodiquement et est plus appropriée si la carte des partitions change peu fréquemment. En outre, la base de données du gestionnaire de la carte des partitions ne doit pas nécessairement être créée à l’aide d’un niveau de tarification Premium.

La fonction Base de données élastique présente deux schémas de mappage des données vers les shardlets et de stockage dans ces derniers :

- Une carte de partitions de liste décrit une association entre la clé unique et un shardlet. Par exemple, au sein d’un système mutualisé, les données relatives à chaque client peuvent être associées à une clé unique et stockées dans leur propre shardlet. Afin de garantir la confidentialité et l’isolement (pour empêcher un client d’épuiser les ressources de stockage de données disponibles pour d’autres), chaque shardlet peut être stocké au sein de sa propre partition.

![](media/best-practices-data-partitioning/PointShardlet.png)

_Figure 4 : Utilisation d’une carte de partitions de liste pour stocker les données d’un client au sein de partitions distinctes_

- Une carte de partitions de plage décrit une association entre un jeu de valeurs de clé contiguës et un shardlet. Dans l’exemple d’architecture mutualisée décrit précédemment, vous pouvez, comme alternative à la mise en œuvre de shardlets dédiés, regrouper les données d’un jeu de clients (chacun présentant sa propre clé) au sein du même shardlet. Ce schéma est moins onéreux que le premier (les clients partagent les ressources de stockage de données), mais présente un risque de baisse de la confidentialité et de l’isolement des données.

![](media/best-practices-data-partitioning/RangeShardlet.png)

_Figure 5 : Utilisation d’une carte de partitions de plage pour stocker des données relatives à une plage de clients au sein d’une partition_

Remarquez qu’une même partition peut comporter des données relatives à plusieurs shardlets. Par exemple, vous pouvez utiliser des shardlets de liste pour stocker des données relatives à différents clients non contigus au sein de la même partition. Vous pouvez aussi associer des shardlets de plage et des shardlets de liste au sein d’une même partition, bien qu’ils seront interrogés par le biais de différentes cartes au sein de la base de données du gestionnaire global des cartes des partitions (la base de données du gestionnaire global des cartes des partitions peut comporter plusieurs cartes des partitions). La figure 6 illustre cette approche.

![](media/best-practices-data-partitioning/MultipleShardMaps.png)

_Figure 6 : Mise en œuvre de plusieurs cartes des partitions_

Le schéma de partitionnement que vous mettez en œuvre peut avoir une incidence considérable sur les performances de votre système et également affecter la fréquence à laquelle les partitions doivent être ajoutées ou supprimées, ou à laquelle les données doivent être repartitionnées entre les partitions. Considérez les points suivants lorsque vous utilisez la fonction Base de données élastique pour partitionner des données :

- Regroupez les données utilisées conjointement au sein d’une même partition et évitez les opérations nécessitant un accès à des données présentes au sein de plusieurs partitions. N’oubliez pas qu’avec la fonction Base de données élastique, une partition constitue une base de données SQL à part entière et que Base de données SQL Azure ne prend pas en charge les jointures entre bases de données. De telles opérations doivent donc être réalisées côté client. Souvenez-vous également qu’avec Base de données SQL Azure, les contraintes d’intégrité référentielle, les déclencheurs et les procédures stockées au sein d’une base de données ne peuvent pas référencer des objets présents au sein d’une autre. Aussi, ne concevez pas un système présentant des dépendances entre les partitions. Cependant, une base de données SQL peut comporter des tables contenant des copies des données de référence fréquemment utilisées par les requêtes et d’autres opérations, et ces tables ne doivent pas nécessairement appartenir à shardlet spécifique. Le fait de répliquer ces données sur des partitions peut permettre de s’affranchir de la nécessité de consulter des données présentes au sein de différentes bases de données. Dans l’idéal, ces données doivent être statiques ou lentes afin de réduire les efforts de réplication et de diminuer le risque qu’elles deviennent obsolètes.

	> [AZURE.NOTE]Bien que Base de données SQL Azure ne prenne pas en charge les jointures entre bases de données, l’API Base de données élastique vous permet d’effectuer des requêtes sur plusieurs partitions qui peuvent parcourir de manière transparente les données stockées au sein de tous les shardlets référencés par une carte des partitions. L’API Base de données élastique répartit les requêtes sur plusieurs partitions en une série de requêtes individuelles (une pour chaque base de données), puis fusionne les résultats. Pour plus d’informations, consultez la page [Requête sur plusieurs partitions] sur le site Web de Microsoft.

- Les données stockées au sein des shardlets appartenant à la même carte des partitions doivent présenter le même schéma. Par exemple, ne créez pas une carte de partitions de liste pointant vers des shardlets comportant des données relatives aux clients et d’autres shardlets comportant des informations relatives aux produits. Cette règle n’est pas indispensable pour la fonction Base de données élastique, mais la gestion et l’interrogation des données deviennent très complexes si chaque shardlet présente un schéma différent. Dans l’exemple que nous venons de citer, il vous faut créer deux cartes de partitions de liste, l’une faisant référence aux données relatives aux clients et l’autre aux informations relatives aux produits. N’oubliez pas que les données appartenant à différentes shardlets peuvent être stockées au sein de la même partition.

	> [AZURE.NOTE]La fonctionnalité de requête entre partitions de l'API Base de données élastique dépend de chaque shardlet dans la carte de partitions contenant le même schéma.
- Les opérations transactionnelles sont uniquement prises en charge pour les données stockées au sein de la même partition et non pas au sein de différentes partitions. Les transactions peuvent être stockées au sein de différents shardlets tant qu’elles font partie de la même partition. Par conséquent, si votre logique professionnelle nécessite la réalisation de transactions, stockez les données concernées au sein de la même partition ou mettez en œuvre la cohérence finale. Pour plus d’informations, reportez-vous aux recommandations en matière de cohérence des données.
- Disposez les partitions à proximité des utilisateurs qui accèdent aux données stockées au sein de ces partitions (géolocalisez les partitions). Cette stratégie permet de réduire la latence.
- Évitez de disposer de diverses partitions très actives (zones sensibles) et de partitions relativement inactives. Essayer de répartir la charge de manière homogène entre les partitions. Cela peut signifier un hachage nécessaire des clés de shardlet.
- Si vous géolocalisez des partitions, assurez-vous que la carte des clés hachées renvoie vers les shardlets stockés au sein des partitions stockées à proximité des utilisateurs qui accèdent à ces données.
- Actuellement, seul un jeu limité de types de données SQL est pris en charge en tant que clés de shardlet : _int, bigint, varbinary,_ et _uniqueidentifier_. Les types SQL _int_ et _bigint_ correspondent aux types de données _int_ et _long_ en C# ; ils présentent les mêmes plages. Le type SQL _varbinary_ peut être géré à l’aide d’un tableau _Byte_ en C# et le type SQL _uniqueidentier_ correspond à la classe _Guid_ de .NET Framework.

Comme son nom l’indique, la fonction Base de données élastique permet à un système d’ajouter et de supprimer des partitions à mesure que le volume de données augmente et diminue. Les API de la Bibliothèque cliente Base de données élastique Base de données SQL Azure permettent à une application de créer et de supprimer des partitions de manière dynamique (et de mettre à jour le gestionnaire des cartes des partitions de manière transparente), mais la suppression d’une partition correspond à une opération nécessitant également la suppression de toutes les données présentes au sein de cette partition. Si une application doit fractionner une partition en deux partitions distinctes ou associer des partitions, la fonction Base de données élastique propose un service distinct de fractionnement et de fusion. Ce service s’exécute au sein d’un service hébergé dans le cloud (le développeur doit créer ce service hébergé dans le cloud) et prend en charge la migration des données entre les partitions en toute sécurité. Pour plus d'informations, consultez la rubrique [Mise à l'échelle à l’aide de l'outil de fractionnement et de fusion de bases de données élastiques] sur le site Web de Microsoft.

## Stratégies de partitionnement pour Azure Storage

Azure Storage présente trois abstractions concernant la gestion des données :

- Le stockage de tables, qui met en œuvre un stockage à structure évolutive. Une table contient une collection d’entités, dont chacune peut comprendre un jeu de propriétés et de valeurs.
- Le stockage d’objets blob, qui permet de stocker des fichiers et des objets de grande taille.
- Les files d’attente de stockage, lesquelles prennent en charge la messagerie asynchrone fiable entre les applications.

Le stockage de tables et le stockage d’objets blob correspondent essentiellement à des magasins de valeurs de clé optimisés pour le stockage respectif de données structurées et non structurées. Les files d’attente de stockage constituent un mécanisme permettant de créer des applications évolutives faiblement couplées. Le stockage de tables, le stockage d’objets blob et les files d’attente de stockage sont créés au sein d’un compte de stockage Azure. Les comptes de stockage Azure prennent en charge trois formes de redondance :

- Le stockage localement redondant, lequel conserve trois copies des données au sein d’un centre de données unique. Cette forme de redondance fournit une protection contre les défaillances matérielles, mais pas contre un incident affectant la totalité du centre de données.
- Le stockage de zone redondant, lequel conserve trois copies des données réparties au sein de différents centres de données présents dans la même région (ou deux régions géographiques proches). Cette forme de redondance permet une protection contre les incidents se produisant au sein d’un centre de données unique, mais pas contre des déconnexions à grande échelle du réseau qui affectent une région tout entière. Remarquez que le stockage de zone redondant est actuellement uniquement disponible pour les objets blob de blocs.
- Le stockage géoredondant, lequel conserve six copies des données : trois copies au sein d’une région (votre région locale) et trois autres copies au sein d’une région distante. Cette forme de redondance fournit le plus haut niveau de protection contre les incidents.

Microsoft a publié des objectifs d’évolutivité pour les comptes de stockage Azure ; consultez la page [Objectifs de performance et évolutivité d’Azure Storage] sur le site Web de Microsoft. Actuellement, la capacité totale relative aux comptes de stockage (taille des données contenues dans le stockage de tables, le stockage d’objets blob et les messages en attente conservés dans la file d’attente de stockage) ne peut pas dépasser 500 To. La vitesse maximale d’une demande (pour une entité, un objet blob ou un message d’une taille d’1 Ko) est de 20 Ko par seconde. Si votre système est susceptible de dépasser ces limites, envisagez le partitionnement de la charge entre plusieurs comptes de stockage ; un seul abonnement Azure permet de créer jusqu’à 100 comptes de stockage. Il est cependant à noter que ces limites peuvent évoluer au fil du temps.

## Partitionner le stockage de tables Azure

Le stockage de tables Azure correspond à une clé ou une valeur stockée, conçue pour le partitionnement. Toutes les entités sont stockées au sein d’une partition et les partitions sont gérées en interne par le stockage de tables Azure. Chaque entité stockée dans une table doit présenter une clé en deux parties comprenant les clés suivantes :

- La clé de partition : il s’agit d’une valeur de chaîne qui détermine la partition dans laquelle le stockage de tables Azure placera l’entité. Toutes les entités présentant la même clé de partition sont stockées au sein de la même partition.
- La clé de ligne : il s’agit d’une autre valeur de chaîne qui identifie l’entité au sein de la partition. Toutes les entités présentes au sein d’une partition sont triées par ordre croissant lexical selon cette clé. La combinaison de la clé de partition et de la clé de ligne doit être unique pour chaque entité et sa longueur ne peut pas dépasser 1 Ko.

Le reste des données relatives à une entité est composé de champs définis par l’application. Aucun schéma particulier n’est appliqué et chaque ligne peut contenir un jeu différent de champs définis par l’application. La seule limite concerne la taille maximale d’une entité (notamment les clés de partition et de ligne) qui est actuellement d’1 Mo. La taille maximale d’une table est de 200 To, même si ces chiffres peuvent évoluer à l’avenir (consultez la page [Objectifs de performance et évolutivité d’Azure Storage] sur le site Web de Microsoft pour obtenir les dernières informations concernant ces limites. Si vous souhaitez stocker des entités qui dépassent cette capacité, envisagez de les fractionner en plusieurs tables : utilisez le partitionnement vertical et divisez les champs dans les groupes les plus susceptibles de faire l’objet d’un accès conjoint.

La figure 7 illustre la structure logique d’un exemple de compte de stockage (données Contoso) pour une application de commerce électronique fictive. Les comptes de stockage comprennent trois tables (informations relatives aux clients, informations relatives aux produits et informations relatives aux commandes) et chaque table présente plusieurs partitions. Dans la table des informations relatives aux clients, les données sont partitionnées en fonction de la ville dans laquelle se trouve le client et la clé de ligne comporte l’ID du client. Dans la table des informations relatives aux produits, les produits sont partitionnés par catégorie et la clé de ligne comporte le numéro du produit. Dans la table des informations relatives aux commandes, les commandes sont partitionnées selon leur date de passation et la clé de ligne indique l’horaire de réception de la commande. Remarquez que toutes les données sont classées en fonction de la clé de ligne au sein de chaque partition.

![](media/best-practices-data-partitioning/TableStorage.png)

_Figure 7 : Tables et partitions au sein d’un exemple de compte de stockage_

> [AZURE.NOTE]Le stockage de tables Azure ajoute également un champ d’horodatage à chaque entité. Le champ d’horodatage est géré par le stockage de tables et actualisé à chaque modification et réinscription de l’entité dans une partition. Le service de stockage de tables utilise ce champ pour mettre en œuvre l’accès concurrentiel optimiste (à chaque fois qu’une application réinscrit une entité dans le stockage de tables, le service de stockage de tables compare la valeur de l’horodatage de l’entité en cours d’écriture avec la valeur présente dans le stockage de tables ; si elles diffèrent, c’est qu’une autre application a dû modifier l’entité depuis sa récupération et l’opération d’écriture échoue). Vous ne devez pas modifier ce champ dans votre propre code et ne devez pas spécifier une valeur pour ce champ lorsque vous créez une nouvelle entité.

Le stockage de tables Azure utilise la clé de partition pour déterminer la méthode de stockage des données. Si une entité est ajoutée à une table avec une clé de partition précédemment inutilisée, le stockage de tables Azure crée une nouvelle partition pour cette entité. Les autres entités présentant la même clé de partition sont stockées au sein de la même partition. Ce mécanisme met efficacement en œuvre une stratégie de montée en puissance automatique. Chaque partition est stockée sur un serveur unique au sein d’un centre de données Azure (afin de s’assurer que les requêtes récupérant des données à partir d’une partition unique s’exécutent rapidement), mais il est possible de répartir différentes partitions sur plusieurs serveurs. En outre, un serveur unique peut héberger plusieurs partitions si ces dernières sont limitées en taille.

Considérez les points suivants lorsque vous concevez vos entités pour le stockage de tables Azure :

- La sélection des valeurs des clés de partition et des clés de ligne doit être motivée en fonction de la méthode d’accès aux données. Vous devez choisir une combinaison de clé de partition et de clé de ligne prenant en charge la majorité de vos requêtes. Les requêtes les plus efficaces récupèrent les données en spécifiant la clé de partition et la clé de ligne. Les requêtes qui spécifient une clé de partition et une plage de clés de ligne peuvent être traitées en analysant une seule partition ; il s’agit d’une opération relativement rapide, dans la mesure où les données sont stockées par ordre des clés de ligne. Les requêtes qui ne spécifient pas au moins la clé de partition peuvent obliger le stockage de tables Azure à analyser chaque partition pour rechercher vos données.

	> [AZURE.TIP]Si une entité présente une clé naturelle, utilisez-la alors en tant que clé de partition et spécifiez une chaîne vide en tant que clé de ligne. Si une entité présente une clé composite comprenant deux propriétés, sélectionnez la propriété variable la plus lente en tant que clé de partition et l’autre en tant que clé de ligne. Si une entité présente plus de deux propriétés de clé, utilisez une concaténation des propriétés pour spécifier les clés de partition et de ligne.

- Si vous effectuez régulièrement des requêtes pour rechercher des données à l’aide de champs autres que les clés de partition et de ligne, envisagez de mettre en œuvre le modèle de table d’index [Index Table Pattern] (en anglais).
- Si vous générez les clés de partition à l’aide d’une séquence incrémentielle croissante ou décroissante unitone (par exemple, « 0001 », « 0002 », « 0003 », etc.) et que chaque partition contient uniquement une quantité limitée de données, le stockage de tables Azure peut alors regrouper physiquement ces partitions sur le même serveur. Ce mécanisme suppose que l’application est plus susceptible d’effectuer des requêtes sur une plage contiguë de partitions (requêtes de plage) et est optimisée pour cet usage. Cependant, cette approche peut conduire à la présence de zones sensibles axées sur un seul serveur, dans la mesure où toutes les insertions de nouvelles entités seront probablement concentrées sur l’une ou l’autre des extrémités des plages contiguës. Elle peut également réduire l’évolutivité. Pour répartir la charge de manière plus homogène entre les serveurs, envisagez de hacher la clé de partition pour rendre la séquence plus aléatoire.
- Le stockage de tables Azure prend en charge les opérations transactionnelles pour les entités appartenant à la même partition. Cela signifie qu’une application peut effectuer plusieurs opérations d’insertion, de mise à jour, de suppression, de remplacement ou de fusion sous forme d’unité atomique (selon la transaction, pas plus de 100 entités et taille de la charge utile de la demande ne dépassant pas 4 Mo). Les opérations relatives à plusieurs partitions ne sont pas transactionnelles et peuvent vous obliger à mettre en œuvre la cohérence finale, comme décrit dans les conseils relatifs à la cohérence des données. Pour plus d’informations sur le stockage de tables et les transactions, consultez la page [Exécution de transactions de groupe d’entités] sur le site Web de Microsoft.
- Accordez une attention particulière à la précision de la clé de partition :
	- Le fait d’utiliser la même clé de partition pour chaque entité conduira le service de stockage de tables à créer une seule partition volumineuse stockée sur un serveur, l’empêchant ainsi de monter en puissance et concentrant la charge sur un seul serveur. Par conséquent, cette approche convient uniquement pour les systèmes qui gèrent un nombre restreint d’entités. Cependant, cette approche garantit que toutes les entités peuvent participer aux transactions relatives à des groupes d’entités.
	- Le fait d’utiliser une clé de partition unique pour chaque entité conduira le service de stockage de tables à créer une partition distincte pour chaque entité, ce qui peut mener à la création d’un grand nombre de petites partitions (selon la taille des entités). Cette approche est plus évolutive que l’utilisation d’une clé de partition unique, mais les transactions relatives à des groupes d’entités ne sont pas possibles et les requêtes intervenant sur plusieurs entités peuvent impliquer une lecture à partir de plusieurs serveurs. Cependant, si l’application effectue des requêtes de plage, l’utilisation d’une séquence unitone pour générer les clés de partition peut permettre d’optimiser ces requêtes.
	- Le fait de partager la clé de partition au sein d’un sous-ensemble d’entités vous permet de regrouper les entités associées au sein de la même partition. Les opérations qui impliquent des entités associées peuvent être effectuées à l’aide de transactions relatives à des groupes d’entités et les requêtes intervenant sur un jeu d’entités associées peuvent être traitées en accédant à un seul serveur.

Pour plus d’informations sur le partitionnement des données dans le stockage de tables Azure, consultez l’article [Guide de conception de table Azure Storage] sur le site Web de Microsoft.

## Partitionner le stockage d’objets blob Azure 

Le stockage d’objets blob Azure vous permet d’organiser des objets binaires volumineux, actuellement jusqu’à 200 Go pour les objets blob de blocs ou 1 To pour les objets blob de pages (pour obtenir les informations les plus récentes, consultez la page [Objectifs de performance et évolutivité d’Azure Storage] sur le site Web de Microsoft). Utilisez des objets blob de blocs dans des situations telles que la diffusion en continu, lorsque vous devez téléverser ou télécharger rapidement d’importants volumes de données. Utilisez des objets blob de pages pour les applications nécessitant un accès aléatoire plutôt qu’en série à certaines parties des données.

Chaque objet blob (de blocs ou de pages) est stocké au sein d’un conteneur dans un compte de stockage Azure. Vous pouvez utiliser des conteneurs pour regrouper des objets blob associés présentant les mêmes exigences de sécurité, bien que ce regroupement soit plus logique que physique. Au sein d’un conteneur, chaque objet blob présente un nom unique.

Le stockage d’objets blob est automatiquement partitionné en fonction du nom de l’objet blob. Chaque objet blob est stocké au sein de sa propre partition et les objets blob présents au sein d’un même conteneur ne partagent pas de partition. Cette architecture permet au stockage d’objets blob Azure d’équilibrer la charge entre les serveurs en toute transparence, dans la mesure où différents objets blob présents au sein du même conteneur peuvent être répartis sur différents serveurs.

Les actions d’écriture d’un seul bloc (objet blob de blocs) ou page (objet blob de pages) sont atomiques, mais pas les opérations intervenant sur des blocs, des pages ou des objets blob. S’il vous faut garantir la cohérence lorsque vous réalisez des opérations d’écriture entre des blocs, des pages et des objets blob, vous devez désactiver un verrou d’écriture à l’aide d’un bail d’objet blob.

Le stockage d’objets blob Azure prend en charge des taux de transfert allant jusqu’à 60 Mo par seconde ou 500 demandes par seconde pour chaque objet blob. Si vous prévoyez de dépasser ces limites et que les données d’objets blob sont relativement statiques, envisagez de répliquer les objets blob à l’aide du réseau de distribution de contenu (CDN) Azure. Pour plus d’informations, consultez la page [Utilisation du réseau de distribution de contenu (CDN) Azure] sur le site Web de Microsoft. Pour obtenir des instructions supplémentaires et examiner des considérations, consultez l’article Réseau de distribution de contenu (CDN).

## Partitionner les files d’attente de stockage

Les files d’attente de stockage Azure vous permettent de mettre en œuvre une messagerie asynchrone entre les processus. Un compte de stockage Azure peut contenir un nombre illimité de files d’attente, et chaque file d’attente peut contenir un nombre illimité de messages. La seule limite concerne l’espace disponible au sein du compte de stockage. La taille maximale d’un message individuel est de 64 Ko. Si vous devez utiliser des messages dont la taille est supérieure, envisagez plutôt d’utiliser des files d’attente Service Bus Azure.

Chaque file d’attente de stockage dispose d’un nom unique au sein du compte de stockage qui la contient. Les files d’attente de partitions Azure basées sur le nom et tous les messages de la même file d’attente sont stockés au sein de la même partition, contrôlée par un serveur unique. Différentes files d’attente peuvent être gérées par différents serveurs afin d’équilibrer la charge. La répartition des files d’attente entre les serveurs est transparente pour les applications et les utilisateurs. Au sein d’une application à grande échelle, n’utilisez pas la même file d’attente de stockage pour toutes les instances de l’application, cette approche pouvant transformer le serveur qui héberge la file d’attente en zone sensible. Utilisez différentes files d’attente pour les différentes zones fonctionnelles de l’application. Les files d’attente de stockage Azure ne prennent pas en charge les transactions. Ainsi, le fait de diriger les messages vers différentes files d’attente ne présente que des répercussions limitées sur la cohérence de la messagerie.

Une file d’attente de stockage Azure peut gérer jusqu’à 2 000 messages par seconde. Si vous devez traiter les messages à une vitesse supérieure, envisagez de créer plusieurs files d’attente. Par exemple, au sein d’une application globale, créez des files d’attente de stockage distinctes au sein de comptes de stockage distincts pour gérer les instances de l’application en cours d’exécution dans chaque région.

## Stratégies de partitionnement pour Azure Service Bus

Azure Service Bus utilise un processus Broker de messages pour gérer les messages envoyés à une file d’attente ou une rubrique Service Bus. Par défaut, tous les messages envoyés à une file d’attente ou une rubrique sont gérés par le même processus Broker de messages. Cette architecture peut imposer une limite concernant le débit global de la file d’attente des messages. Cependant, vous pouvez également partitionner une file d’attente ou une rubrique lorsqu’elle est créée en définissant la propriété _EnablePartitioning_ de la description de file d’attente ou rubrique sur la valeur _true_. Une file d’attente ou une rubrique partitionnée est divisée en plusieurs fragments, chacun d’entre eux est soutenu par une banque de messages et un processus Broker de messages distincts. Service Bus prend en charge la création et la gestion de ces fragments. Lorsqu’une application publie un message à destination d’une file d’attente ou d’une rubrique partitionnée, Service Bus attribue ce message à un fragment de cette file d’attente ou rubrique. Lorsqu’une application reçoit un message à partir d’une file d’attente ou d’un abonnement, Service Bus vérifie chaque fragment pour identifier le message suivant disponible et le transmet ensuite à l’application pour le traiter. Cette structure favorise la répartition de la charge entre les processus Broker de messages et les banques de messages, permettant ainsi d’augmenter l’évolutivité et d’améliorer la disponibilité. Si la banque de messages ou le processus Broker de messages relatif un fragment est temporairement indisponible, Service Bus peut récupérer des messages à partir d’un des fragments restants disponibles.

Service Bus attribue un message à un fragment comme suit :

- Si le message appartient à une session, tous les messages présentant la même valeur concernant la propriété \_SessionId\_ sont envoyés au même fragment.
- Si le message n’appartient pas à une session, mais que l’expéditeur a spécifié une valeur concernant la propriété _PartitionKey_, tous les messages présentant la même valeur _PartitionKey_ sont alors envoyés au même fragment.

	> [AZURE.NOTE]Si les propriétés _SessionId_ et _PartitionKey_ sont toutes deux spécifiées, elles doivent être définies sur la même valeur. Sinon, le message sera rejeté.
- Si les propriétés _SessionId_ et _PartitionKey_ d’un message ne sont pas spécifiées, mais que la détection des doublons est activée, la propriété _MessageId_ est utilisée. Tous les messages présentant la même propriété _MessageId_ sont dirigés vers le même fragment.
- Si des messages ne présentent aucune propriété _SessionId, PartitionKey,_ ou _MessageId_, Service Bus attribue alors les messages aux fragments de manière alternée. Si un fragment n’est pas disponible, Service Bus passe au suivant. De cette manière, une défaillance temporaire de l’infrastructure de la messagerie n’entraîne pas de défaillance de l’opération d’envoi des messages.

Considérez les points suivants lorsque vous décidez ou non de partitionner une rubrique ou une file d’attente de messages Service Bus, et à l’aide de quelle méthode :

- Les rubriques et files d’attente Service Bus sont créées dans l’étendue d’un espace de nom Service Bus. Service Bus permet actuellement de disposer jusqu’à 100 rubriques ou files d’attente par espace de nom.
- Chaque espace de nom Service Bus impose des quotas sur les ressources disponibles, telles que le nombre d’abonnements par rubrique, le nombre d’envois et de réceptions simultanés de demandes par seconde et le nombre maximum de connexions simultanées pouvant être établies. Ces quotas sont documentés sur la page [Quotas de Service Bus] sur le site Web de Microsoft. Si vous pensez dépasser ces valeurs, créez des espaces de nom supplémentaires disposant de leurs propres rubriques et files d’attente, puis répartissez le travail entre ces espaces de nom. Par exemple, au sein d’une application globale, créez des espaces de noms distincts dans chaque région et configurez les instances applicatives pour utiliser les rubriques et les files d’attente présentes au sein de l’espace de nom le plus proche.
- Les messages envoyés dans le cadre d’une transaction doivent spécifier une clé de partition. Il peut s’agir d’une propriété _SessionId, PartitionKey,_ ou _MessageId_. Tous les messages envoyés dans le cadre de la même transaction doivent spécifier la même clé de partition, car ils doivent être gérés par le même processus Broker de messages. Vous ne pouvez pas envoyer des messages à différentes files d’attente ou rubriques au sein de la même transaction.
- Vous ne pouvez pas configurer une file d’attente ou une rubrique partitionnée pour qu’elle soit automatiquement supprimée lorsqu’elle devient inactive.
- Si vous procédez à la création de solutions interplateformes ou hybrides, vous ne pouvez actuellement pas utiliser des files d’attente et des rubriques partitionnées avec le protocole AMQP (Advanced Message Queuing Protocol).

## Stratégies de partitionnement pour Azure DocumentDB

Azure DocumentDB correspond à une base de données NoSQL pouvant stocker des documents. Un document de DocumentDB correspond à une représentation sérialisée JSON d’un objet ou autre élément de données. Aucun schéma fixe n’est appliqué, mais chaque document doit contenir un ID unique.

Les documents sont organisés en collections. Une collection vous permet de regrouper des documents connexes. Par exemple, au sein d’un système gérant des publications de blog, vous pouvez stocker le contenu de chaque publication de blog sous forme de document au sein d’une collection et créer des collections pour chaque type d’objet. Autrement, au sein d’une application mutualisée, telle un système permettant aux différents auteurs de contrôler et de gérer leurs propres publications de blog, vous pouvez partitionner les blogs par auteur et créer une collection distincte pour chaque auteur. L’espace de stockage alloué aux collections est flexible et peut évoluer à la hausse ou à la baisse en fonction des besoins.

Les collections de documents fournissent un mécanisme naturel permettant de partitionner des données au sein d’une base de données unique. En interne, une base de données DocumentDB peut s’étendre sur plusieurs serveurs, et DocumentDB peut tenter de répartir la charge en distribuant les collections sur les serveurs. La méthode la plus simple permettant de mettre en œuvre le partitionnement consiste à créer une collection pour chaque partition.

> [AZURE.NOTE]Chaque base de données DocumentDB se voit attribuée des ressources selon un _niveau de performance_. À chaque niveau de performance est associé un taux limite d’_unités de demande_. Le taux limite d’unités de demande spécifie le volume des ressources réservées pour cette collection et son utilisation est exclusivement disponible pour cette collection. Le coût d’une collection dépend du niveau de performance sélectionné pour cette collection ; plus le niveau de performance (et le taux limite limite d’unités de demande) est élevé, plus la charge l’est également. Vous pouvez modifier le niveau de performance d’une collection à l’aide du portail de gestion Azure. Pour plus d’informations, consultez la page [Niveaux de performances dans DocumentDB] sur le site Web de Microsoft.

Toutes les bases de données sont créées dans le cadre d’un compte DocumentDB. Un seul compte DocumentDB peut contenir plusieurs bases de données et indique dans quelle région les bases de données sont créées. Chaque compte DocumentDB impose également son propre contrôle d’accès. Vous pouvez utiliser des comptes DocumentDB pour géolocaliser les partitions (collections au sein des bases de données) situées à proximité des utilisateurs ayant besoin d’y accéder et appliquer des restrictions afin que seuls ces utilisateurs puissent s’y connecter.

Chaque compte DocumentDB présente un quota qui limite le nombre de bases de données et de collections pouvant être contenues, ainsi que la quantité de stockage de documents disponible. Bien que ces limites soient susceptibles d’évoluer, elles sont décrites sur la page [Limites dans la version préliminaire de DocumentDB] sur le site Web de Microsoft. Si vous mettez en œuvre un système au sein duquel toutes les partitions appartiennent à la même base de données, vous pouvez, en théorie, atteindre la limite de capacité de stockage du compte. Dans ce cas, vous devez créer des comptes et bases de données DocumentDB supplémentaires et répartir les partitions entre ces bases de données. Cependant, même si vous n’êtes pas susceptible d’atteindre la capacité de stockage d’une base de données, le fait que chaque base de données dispose de son propre jeu d’utilisateurs et d’autorisations constitue une bonne raison d’utiliser plusieurs bases de données. Vous pouvez utiliser ce mécanisme pour isoler l’accès aux collections en fonction des différentes bases de données.

La figure 8 illustre la structure de haut niveau de l’architecture DocumentDB.

![](media/best-practices-data-partitioning/DocumentDBStructure.png)

_Figure 8 : La structure de DocumentDB_

Il incombe à l’application cliente d’envoyer les requêtes vers la partition appropriée, généralement en mettant en œuvre son propre mécanisme de mappage en fonction de certains attributs relatifs aux données qui définissent la clé de partitionnement. La figure 9 illustre deux bases de données DocumentDB, chacune contenant deux collections fonctionnant en tant que partitions. Les données sont partitionnées par ID de locataire et concernent un client spécifique. Les bases de données sont créées dans des comptes DocumenDB distincts, lesquels sont situés dans la même région que les clients dont elles contiennent les données. La logique de routage de l’application cliente utilise l’ID de client en tant que clé de partition.

![](media/best-practices-data-partitioning/DocumentDBPartitions.png)

_Figure 9 : Mise en œuvre du partitionnement à l’aide d’Azure DocumentDB_

Considérez les points suivants lorsque vous décidez de partitionner des données à l’aide de DocumentDB :

- Les ressources disponibles pour une base de données DocumentDB sont soumises aux limites de quota du compte DocumentDB. Chaque base de données peut contenir un certain nombre de collections (là encore, dans une certaine limite) et chaque collection est associée à un niveau de performance qui régit le taux limite d’unités de demande (débit réservé) pour cette collection. Pour plus d’informations, consultez la page [Limites dans la version préliminaire de DocumentDB] sur le site Web de Microsoft.
- Chaque document doit présenter un attribut pouvant être utilisé pour identifier de manière unique ce document au sein de la collection dans laquelle il est stocké. Cet attribut est différent de la clé de partition qui définit la collection dans laquelle le document est stocké. Une collection peut contenir un grand nombre de documents, un nombre en théorie uniquement limité par la longueur maximale de l’ID du document. L’ID du document peut comprendre jusqu’à 255 caractères.
- Toutes les opérations relatives à un document sont exécutées dans le cadre d’une transaction qui s’étend à la collection dans laquelle le document est stocké. Si une opération échoue, la tâche réalisée est annulée. Lorsqu’un document est soumis à une opération, toutes les modifications apportées sont soumises à un isolement de niveau capture instantanée. Ce mécanisme garantit que si, par exemple, une requête visant à créer un nouveau document échoue, un autre utilisateur qui interroge la base de données simultanément ne consulte pas un document partiel supprimé par la suite.
- Les requêtes DocumentDB sont également limitées au niveau de la collection. Une seule requête peut uniquement récupérer les données issues d’une collection. Si vous devez extraire des données issues de plusieurs collections, vous devez interroger chaque collection individuellement et fusionner les résultats dans votre code applicatif.
- DocumentDB prend en charge les éléments programmables pouvant tous être stockés au sein d’une collection avec les documents suivants : procédures stockées, fonctions définies par l’utilisateur et déclencheurs (rédigés en JavaScript). Ces éléments peuvent accéder à n’importe quel document au sein de la même collection. En outre, ces éléments s’exécutent soit dans le cadre de la portée de la transaction actuelle (dans le cas d’un déclencheur intervenant suite à une opération de création, de suppression ou de remplacement effectuée sur un document), soit en démarrant une nouvelle transaction (dans le cas d’une procédure stockée exécutée suite à une demande client explicite). Si le code d’un élément programmable lève une exception, la transaction est annulée. Vous pouvez utiliser des procédures stockées et des déclencheurs pour maintenir l’intégrité et la cohérence entre des documents, mais ces documents doivent tous faire partie de la même collection.
- Vous devez vous assurer que les collections que vous souhaitez conserver au sein des bases de données dans un compte DocumentDB sont peu susceptibles de dépasser les limites de débit définies par les niveaux de performance des collections. Ces limites sont décrites sur la page [Gestion des capacités et performances de DocumentDB] sur le site Web de Microsoft. Si vous prévoyez d’atteindre ces limites, envisagez de fractionner les collections des bases de données entre différents comptes DocumentDB afin de réduire la charge par collection.

## Stratégies de partitionnement pour Azure Search

La possibilité de rechercher des données constitue souvent la principale méthode de navigation et d’exploration fournie par de nombreuses applications Web, permettant aux utilisateurs de trouver rapidement des ressources (par exemple, des produits au sein d’une application de commerce électronique) en fonction de combinaisons de critères de recherche. Le service de recherche Azure Search propose des fonctionnalités de recherche en texte intégral dans le contenu Web, ainsi que des fonctionnalités telles que les requêtes prédictives, les requêtes suggérées en fonction des correspondances suivantes et la navigation à facettes. Une description complète de ces fonctionnalités est disponible sur la page [Qu’est-ce qu’Azure Search ?] sur le site Web de Microsoft.

Le service de recherche stocke le contenu pouvant faire l’objet d’une recherche sous forme de documents JSON au sein d’une base de données. Vous définissez des index qui spécifient les champs de recherche dans ces documents et fournissent ces définitions au service de recherche. Lorsqu’un utilisateur soumet une demande de recherche, le service de recherche utilise les index appropriés pour trouver les éléments correspondants.

Pour réduire la contention, le stockage utilisé par le service de recherche peut être divisé en 1, 2, 3, 4, 6, ou 12 partitions, et chaque partition peut être répliquée jusqu’à 6 fois. Le produit du nombre de partitions multiplié par le nombre de répliques est appelé _unité de recherche_. Une seule instance du service de recherche peut contenir au maximum 36 unités de recherche (une base de données comportant 12 partitions prend en charge 3 répliques au maximum). La facturation se fait en fonction de chaque unité de recherche allouée à votre service. À mesure que le volume de contenu pouvant faire l’objet d’une recherche augmente ou que le taux des demandes de recherche s’accroît, vous pouvez ajouter des unités de recherche à une instance existante du service de recherche pour gérer la charge supplémentaire. Le service de recherche se charge lui-même de répartir les documents de manière homogène entre les partitions ; aucune stratégie de partitionnement manuel n’est actuellement prise en charge.

Chaque partition peut contenir un maximum de 15 millions de documents ou occuper 300 Go d’espace de stockage (limite la plus faible, en fonction de la taille de vos documents et index). Vous pouvez créer jusqu’à 50 index. Les performances du service varient selon la complexité des documents, les index disponibles et la latence du réseau. En moyenne, une seule réplique (1 unité de recherche) peut gérer 15 requêtes par seconde, même s’il convient de réaliser une mesure à l’aide de vos propres données pour obtenir un résultat plus précis du débit. Pour plus d’informations, consultez la page [Limites de service d’Azure Search] sur le site Web de Microsoft.

> [AZURE.NOTE]Vous pouvez stocker un jeu de types de données limité au sein des documents pouvant faire l’objet d’une recherche : chaînes, valeurs booléennes, données numériques, données d’horodatage et certaines données géographiques. Pour plus d’informations, consultez la page [Types de données pris en charge (Azure Search)] sur le site Web de Microsoft.

Vous disposez d’un contrôle limité sur la manière dont le service Azure Search partitionne les données relatives à chaque instance du service. Cependant, au sein d’un environnement global, vous pourrez améliorer les performances et réduire la latence et la contention en partitionnant le service à l’aide de l’une des stratégies suivantes :

- Créez une instance du service de recherche dans chaque région géographique et assurez-vous que les applications clientes sont dirigées vers l’instance la plus proche. Cette stratégie exige la réplication de chaque mise à jour du contenu pouvant faire l’objet d’une recherche en temps voulu au sein de toutes les instances du service.
- Créez un service de recherche à deux niveaux : un service local dans chaque région, lequel comporte les données plus fréquemment utilisées par les utilisateurs dans cette région et un service global, lequel englobe toutes les données. Les utilisateurs peuvent diriger les demandes vers le service local (pour des résultats rapides, mais limités) ou vers le service global (pour des résultats plus lents, mais plus complets). Cette approche est plus appropriée lorsque les données faisant l’objet d’une recherche présentent des variations régionales significatives.

## Stratégies de partitionnement pour Cache Redis Azure

Cache Redis Azure propose un service de mise en cache partagé dans le cloud basé sur le magasin de données de clés ou de valeurs Redis. Comme son nom l’indique, le service Cache Redis Azure correspond à une solution de mise en cache et doit donc être uniquement utilisé pour contenir des données temporaires et non pas en tant que magasin de données permanent. Les applications qui utilisent Cache Redis Azure doivent être en mesure de continuer à fonctionner si le cache n’est pas disponible. Cache Redis Azure prend en charge la réplication principale et secondaire pour fournir une haute disponibilité, mais le service limite actuellement la taille maximale du cache à 53 Go. Si vous devez disposer de davantage d’espace, vous devez créer des caches supplémentaires. Pour plus d’informations, consultez la page [Cache Redis Azure] sur le site Web de Microsoft.

Le partitionnement d’un magasin de données Redis implique la répartition des données entre des instances du service Redis. Chaque instance constitue une partition unique. Cache Redis Azure fait abstraction des services Redis derrière une façade et ne les expose pas directement. La méthode la plus simple pour mettre en œuvre le partitionnement consiste à créer plusieurs caches Redis Azure et de répartir les données entre eux. Vous pouvez associer chaque élément de données à un identificateur (une clé de partition) qui indique dans quel cache l’élément doit être stocké. La logique de votre application cliente peut utiliser cet identificateur pour acheminer les requêtes vers la partition appropriée. Ce schéma est très simple, mais si le schéma de partitionnement est modifié (par exemple, si des caches Redis Azure supplémentaires sont créés), il faut reconfigurer les applications clientes.

Le cache Redis natif (pas le cache Redis Azure) prend en charge le partitionnement côté serveur basé sur le clustering Redis. Dans cette approche, les données sont réparties de manière homogène entre les serveurs à l’aide d’un mécanisme de hachage. Chaque serveur Redis stocke les métadonnées décrivant la plage de clés de hachage stockées dans la partition et contient également les informations relatives aux clés de hachage présentes au sein de partitions présentes sur d’autres serveurs. Les applications clientes envoient simplement des requêtes à l’un des participants Redis (généralement, le serveur le plus proche). Le serveur Redis examine la demande du client et, si elle peut être résolue localement, procède à l’opération demandée. Autrement, il transmet la demande au serveur approprié. Ce modèle est mis en œuvre à l’aide du clustering Redis et est décrit plus en détail sur la page (en anglais) [Redis cluster tutorial] sur le site Web de Redis. Le clustering Redis est transparent pour les applications clientes et il est possible d’ajouter des serveurs Redis supplémentaires au cluster (et aux données repartitionnées) sans devoir reconfigurer les clients.

> [AZURE.IMPORTANT]Cache Redis Azure ne prend pas en charge le clustering Redis. Si vous souhaitez mettre en œuvre cette approche avec Azure, vous devez intégrer vos propres serveurs Redis en installant Redis sur un ensemble de machines virtuelles et en les configurant manuellement. La page (en anglais) [Running Redis on a CentOS Linux VM in Azure] sur le site Web de Microsoft présente un exemple décrivant comment créer et configurer un nœud Redis en tant que machine virtuelle Azure.

La page (en anglais) [Partitioning: how to split data among multiple Redis instances] sur le site Web de Redis fournit des informations supplémentaires concernant la mise en œuvre du partitionnement avec Redis. Le reste de cette section part du principe que vous mettez en œuvre le partitionnement côté client ou assisté par proxy.

Considérez les points suivants lorsque vous décidez de partitionner des données à l’aide de Cache Redis Azure :

- Cache Redis Azure n’est pas destiné à fonctionner en tant que magasin de données permanent. Aussi, quel que soit le schéma de partitionnement que vous mettez en œuvre, votre code d’application doit accepter que les données ne soient pas présentes dans le cache et qu’elles doivent être récupérées à partir d’un autre emplacement.
- Conservez les données fréquemment utilisées au sein de la même partition. Redis correspond un magasin de clés ou de valeurs puissant, proposant plusieurs mécanismes hautement optimisés pour structurer les données, depuis de simples chaînes (en réalité, des données binaires d’une longueur allant jusqu’à 512 Mo) jusqu’à des types d’agrégation tels que des listes (pouvant faire office de files d’attente et de piles), des jeux d’éléments (ordonnés et non ordonnés), des hachages (pouvant regrouper les champs associés, tels que les éléments représentant les champs dans un objet). Les types d’agrégation vous permettent d’associer plusieurs valeurs connexes à la même clé. Une clé Redis identifie une liste, un jeu ou un hachage plutôt que les éléments de données contenus. Ces types sont tous disponibles avec Cache Redis Azure et sont décrits sur la page (en anglais) [Data Types] sur le site Web de Redis. Par exemple, dans le cadre d’un système de commerce électronique qui assure le suivi des commandes passées par les clients, les détails de chaque client peuvent être stockés dans un hachage Redis indexé à l’aide de l’ID du client. Chaque hachage peut contenir une collection d’ID de commande relatifs au client. Un jeu Redis distinct peut contenir les commandes, à nouveau structurées sous forme de hachages, indexés à l’aide de l’ID de la commande. La figure 10 illustre cette structure. Remarquez que Redis ne met pas en œuvre toutes les formes d’intégrité référentielle ; il incombe au développeur de maintenir les relations entre les clients et commandes.

![](media/best-practices-data-partitioning/RedisCustomersandOrders.png)

_Figure 10 : Structure suggérée au sein du stockage Redis pour enregistrer les commandes des clients et les détails associés_

> [AZURE.NOTE]Dans Redis, toutes les clés correspondent à des valeurs de données binaires (comme les chaînes Redis) et peuvent contenir jusqu’à 512 Mo de données. En théorie, une clé peut donc contenir pratiquement tout type d’information. Cependant, vous devez adopter une convention d’affectation de noms cohérente concernant les clés et permettant de décrire le type de données et d’identifier l’entité, sans pour autant correspondre à un nom trop long. Une approche courante consiste à utiliser des clés sous la forme « type\_entité:ID », par exemple : « client:99 » pour indiquer la clé correspondant au client présentant l’ID 99.

- Vous pouvez mettre en œuvre le partitionnement vertical en stockant les informations connexes dans des agrégations différentes au sein de la même base de données. Par exemple, au sein d’une application de commerce électronique, vous pouvez stocker les informations relatives aux produits fréquemment utilisées dans une table de hachage Redis et les informations les moins fréquemment utilisées dans une autre. Les deux hachages peuvent utiliser le même ID de produit pour définir la clé, par exemple : « produit:_nn_ », où _nn_ correspond à l’ID du produit relatif aux informations associées et « détails\_produit:_nn_ » pour les informations détaillées. Cette stratégie favorise la réduction du volume de données que la plupart des requêtes sont susceptibles de récupérer.
- Le repartitionnement d’un magasin de données Redis constitue une tâche complexe et chronophage. Le clustering Redis est capable de repartitionner automatiquement les données, mais cette fonctionnalité n’est pas disponible avec Cache Redis Azure. Par conséquent, lorsque vous concevez votre modèle de partitionnement, vous devez laisser suffisamment d’espace libre dans chaque partition pour permettre l’augmentation attendue du volume de données au fil du temps. Cependant, n’oubliez pas que Cache Redis Azure est conçu pour mettre temporairement des données en cache et que les données stockées dans le cache peuvent présenter une durée de vie limitée, spécifiée en tant que valeur de durée de vie. Concernant les données relativement volatiles, la durée de vie doit être courte. En revanche, concernant les données statiques, la durée de vie peut être beaucoup plus longue. Évitez de stocker de grandes quantités de données durables dans le cache si le volume de ces données est susceptible de remplir le cache. Vous pouvez spécifier une stratégie d’éviction permettant à Cache Redis Azure de supprimer les données si l’espace est limité.

	> [AZURE.NOTE]Cache Redis Azure vous permet de spécifier la taille maximale du cache (de 250 Mo à 53 Go) en sélectionnant le niveau de tarification approprié. Cependant, après avoir créé un cache Redis Azure, vous ne pouvez pas en augmenter ni réduire la taille.

- Les lots et transactions Redis ne peuvent pas couvrir plusieurs connexions. Ainsi, toutes les données affectées par un lot ou une transaction doivent être stockées au sein de la même base de données (partition).

	> [AZURE.NOTE]Une séquence d’opérations relative à une transaction Redis n’est pas nécessairement atomique. Les commandes composant une transaction sont vérifiérs et placées en file d’attente avant leur exécution, et si une erreur se produit au cours de cette phase, l’ensemble de la file d’attente est ignoré. Cependant, une fois la transaction envoyée avec succès, les commandes placées en file d’attente sont exécutées en séquence. En cas d’échec d’une commande, seule cette dernière est annulée ; toutes les commandes précédentes et suivantes dans la file d’attente sont effectuées. Si vous devez réaliser des opérations atomiques. Pour plus d’informations, consultez la page (en anglais) [Transactions] sur le site Web de Redis.

- Redis prend en charge un nombre limité d’opérations atomiques, et les seules opérations de ce type prenant en charge plusieurs clés et valeurs sont les commandes MGET (lesquelles renvoient une collection de valeurs pour une liste de clés spécifiée) et MSET (lesquelles peuvent stocker une collection de valeurs pour une liste de clés spécifiée). Si vous devez utiliser ces opérations, les paires de clés et de valeurs référencées par les commandes MSET et MGET doivent être stockées au sein de la même base de données.

## Rééquilibrer les partitions

À mesure qu’un système évolue et que le modèle d’utilisation est davantage compris, il peut être nécessaire d’ajuster le schéma de partitionnement. Cela peut être dû au fait que des partitions individuelles concentrent un volume de trafic disproportionné et deviennent sensibles, ce qui conduit à une contention excessive. En outre, il se peut que vous ayez sous-évalué le volume des données stockées au sein des partitions et que ces partitions atteignent leurs limites en matière de capacité de stockage. Quelle que soit la cause, il est parfois nécessaire de rééquilibrer des partitions pour répartir la charge de manière plus homogène.

Dans certains cas, les systèmes de stockage de données n’indiquant pas explicitement de quelle manière les données sont allouées aux serveurs peuvent rééquilibrer automatiquement les partitions dans les limites des ressources disponibles. Dans d’autres cas, le rééquilibrage correspond à une tâche administrative qui se compose de deux étapes :

1. Déterminer la nouvelle stratégie de partitionnement afin d’identifier les partitions devant être fractionnées (ou éventuellement combinées) et comment allouer des données à ces nouvelles partitions en créant de nouvelles clés de partition.
2. Migrer les données concernées à partir de l’ancien schéma de partitionnement vers le nouveau jeu de partitions.

> [AZURE.NOTE]Le mappage des collections DocumentDB aux serveurs est transparent, mais il se peut que vous atteigniez tout de même les limites en matière de capacité de stockage et de débit d’un compte DocumentDB, auquel cas il vous faudra peut-être revoir votre schéma de partitionnement et migrer les données.

Selon la technologie de stockage de données et la conception de votre système de stockage, vous pouvez éventuellement migrer des données entre les partitions alors même qu’elles sont en cours d’utilisation (migration en ligne). Si ce n’est pas possible, il vous faut peut-être rendre les partitions concernées temporairement indisponibles pendant la migration des données (migration hors ligne).

## Migration hors ligne

La migration hors ligne constitue sans doute l’approche la plus simple, car elle réduit les risques de contention . Les données migrées ne doivent pas être modifiées lors de leur déplacement et de leur restructuration.

Sur le plan conceptuel, ce processus comprend les étapes suivantes :

1. mettre la partition hors ligne ;
2. fractionner ou fusionner et migrer les données vers les nouvelles partitions ;
3. vérifier les données ;
4. mettre les nouvelles partitions en ligne ;
5. supprimer l’ancienne partition.

Afin de conserver une certaine disponibilité, il est possible de mettre la partition d’origine en lecture seule à l’étape 1 au lieu de la rendre indisponible. Cela permet aux applications de lire les données au cours de leur migration, sans que les applications ne puissent les modifier.

## Migration en ligne

La migration en ligne est plus complexe à réaliser, mais entraîne moins de perturbations pour les utilisateurs, les données restant disponibles pendant toute la procédure. Le processus est similaire à celui utilisé pour la migration hors ligne, à ceci près que la partition d’origine n’est pas mise hors ligne (étape 1). Selon la précision du processus de migration (élément par élément ou partition par partition), il se peut que le code d’accès aux données présent dans les applications clientes doive gérer la lecture et l’écriture des données stockées au sein de deux emplacements (la partition d’origine et la nouvelle partition).

Pour obtenir un exemple de solution prenant en charge la migration en ligne, consultez la page [Mise à l’échelle à l’aide de l’outil de fractionnement et de fusion de bases de données élastiques] sur le site Web de Microsoft.

## Conseils et modèles connexes

Les modèles suivants peuvent également s’appliquer à votre cas lorsque vous étudiez des stratégies de mise en œuvre de la cohérence des données :

- La page (en anglais) [Data Consistency Primer] sur le site Web de Microsoft décrit les stratégies de maintien de la cohérence au sein d’un environnement distribué tel que le cloud.
- La page (en anglais) [Data Partitioning Guidance] sur le site Web de Microsoft présente une vue d’ensemble de la conception de partitions visant à satisfaire divers critères au sein d’une solution distribuée.
- La page (en anglais) [Sharding Pattern] sur le site Web de Microsoft récapitule certaines stratégies courantes en matière de partitionnement de données.
- La page (en anglais) [Index Table Pattern] sur le site Web de Microsoft décrit comment créer des index secondaires pour les données. Cette approche permet à une application de récupérer rapidement des données à l’aide de requêtes ne faisant pas référence à la clé principale d’une collection.
- La page (en anglais) [Materialized View Pattern] sur le site Web de Microsoft décrit comment générer des affichages prédéfinis qui synthétisent les données pour prendre en charge des opérations de requête rapide. Cette approche peut s’avérer utile au sein d’un magasin de données partitionnées si les partitions contenant les données synthétisées sont réparties sur plusieurs sites.
- L’article [Utilisation du réseau de distribution de contenu (CDN) Azure] fournit des conseils supplémentaires concernant la configuration et l’utilisation du CDN avec Azure.

## Informations complémentaires

- La page [Qu’est-ce qu’une base de données SQL Azure ?] sur le site Web de Microsoft présente des informations détaillées concernant la création et l’utilisation de bases de données SQL.
- La page [Vue d’ensemble des fonctionnalités de bases de données élastiques] sur le site Web de Microsoft dresse une présentation complète de la fonction Base de données élastique.
- La rubrique [Mise à l’échelle à l’aide de l’outil de fractionnement et de fusion de bases de données élastiques] sur le site Web de Microsoft présente des informations relatives à l’utilisation du service de fractionnement et de fusion pour gérer les partitions de bases de données élastiques.
- La page [Objectifs d’extensibilité et de performances d’Azure Storage](https://msdn.microsoft.com/library/azure/dn249410.aspx) sur le site Web de Microsoft présente les limites actuelles en matière de dimensionnement et de débit sur Azure Storage.
- La page [Exécution de transactions de groupe d’entités] sur le site Web de Microsoft fournit des informations détaillées concernant la mise en œuvre des opérations transactionnelles relatives à des entités stockées au sein du service de stockage de tables Azure.
- L’article [Guide de conception de table Azure Storage] sur le site Web de Microsoft fournit des informations détaillées concernant le partitionnement des données dans le stockage de tables Azure.
- La page [Utilisation du réseau de distribution de contenu (CDN) Azure] sur le site Web de Microsoft décrit comment répliquer des données contenues dans le service de stockage d’objets blob Azure à l’aide du réseau de distribution de contenu (CDN) Azure.
- La page [Gestion des besoins de capacité de DocumentDB] sur le site Web de Microsoft comporte des informations concernant la manière dont DocumentDB Azure alloue des ressources aux bases de données.
- La page [Qu’est-ce qu’Azure Search ?] sur le site Web de Microsoft présente une description complète des fonctionnalités disponibles avec le service Azure Search.
- La page [Limites de service d’Azure Search] sur le site Web de Microsoft comporte des informations concernant la capacité de chaque instance du service Azure Search.
- La page [Types de données pris en charge (Azure Search)] sur le site Web Microsoft présente une synthèse des types de données que vous pouvez utiliser au sein de documents et d’index pouvant faire l’objet d’une recherche.
- La page [Cache Redis Azure] sur le site Web de Microsoft dresse une présentation de Cache Redis Azure.
- La page (en anglais) [Partitioning: how to split data among multiple Redis instances] sur le site Web de Redis fournit des informations concernant la mise en œuvre du partitionnement avec Redis.
- La page (en anglais) [Running Redis on a CentOS Linux VM in Azure] sur le site Web de Microsoft présente un exemple décrivant comment créer et configurer un nœud Redis en tant que machine virtuelle Azure.
- La page (en anglais) [Data Types] sur le site Web de Redis présente les types de données disponibles avec Redis et Cache Redis Azure.

[Cache Redis Azure]: http://azure.microsoft.com/services/cache/
[Objectifs de performance et évolutivité d’Azure Storage]: storage/storage-scalability-targets.md
[Objectifs de performance et évolutivité d’Azure Storage]: storage/storage-scalability-targets.md
[Guide de conception de table Azure Storage]: storage/storage-table-design-guide.md
[Building a Polyglot Solution]: https://msdn.microsoft.com/library/dn313279.aspx
[Data Access for Highly-Scalable Solutions: Using SQL, NoSQL, and Polyglot Persistence]: https://msdn.microsoft.com/library/dn271399.aspx
[Data Consistency Primer]: http://aka.ms/Data-Consistency-Primer
[Data Partitioning Guidance]: https://msdn.microsoft.com/library/dn589795.aspx
[Data Types]: http://redis.io/topics/data-types
[Limites dans la version préliminaire de DocumentDB]: documentdb/documentdb-limits.md
[Vue d’ensemble des fonctionnalités de bases de données élastiques]: sql-database/sql-database-elastic-scale-introduction.md
[utilitaire de migration de fédérations]: https://code.msdn.microsoft.com/vstudio/Federations-Migration-ce61e9c1
[Index Table Pattern]: http://aka.ms/Index-Table-Pattern
[Gestion des besoins de capacité de DocumentDB]: documentdb/documentdb-manage.md
[Gestion des capacités et performances de DocumentDB]: documentdb/documentdb-manage.md
[Materialized View Pattern]: http://aka.ms/Materialized-View-Pattern
[Requête sur plusieurs partitions]: sql-database/sql-database-elastic-scale-multishard-querying.md
[Partitioning: how to split data among multiple Redis instances]: http://redis.io/topics/partitioning
[Niveaux de performances dans DocumentDB]: documentdb/documentdb-performance-levels.md
[Exécution de transactions de groupe d’entités]: https://msdn.microsoft.com/library/azure/dd894038.aspx
[Redis cluster tutorial]: http://redis.io/topics/cluster-tutorial
[Running Redis on a CentOS Linux VM in Azure]: http://blogs.msdn.com/b/tconte/archive/2012/06/08/running-redis-on-a-centos-linux-vm-in-windows-azure.aspx
[Mise à l'échelle à l’aide de l'outil de fractionnement et de fusion de bases de données élastiques]: sql-database/sql-database-elastic-scale-overview-split-and-merge.md
[Mise à l’échelle à l’aide de l’outil de fractionnement et de fusion de bases de données élastiques]: sql-database/sql-database-elastic-scale-overview-split-and-merge.md
[Utilisation du réseau de distribution de contenu (CDN) Azure]: cdn/cdn-how-to-use-cdn.md
[Quotas de Service Bus]: service-bus/service-bus-quotas.md
[Limites de service d’Azure Search]: search/search-limits-quotas-capacity.md
[Sharding pattern]: http://aka.ms/Sharding-Pattern
[Types de données pris en charge (Azure Search)]: https://msdn.microsoft.com/library/azure/dn798938.aspx
[Transactions]: http://redis.io/topics/transactions
[Qu’est-ce qu’Azure Search ?]: search/search-what-is-azure-search.md
[Qu’est-ce qu’une base de données SQL Azure ?]: sql-database/sql-database-technical-overview.md

<!---HONumber=AcomDC_1223_2015-->